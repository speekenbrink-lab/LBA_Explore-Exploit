#Fit some God-Damn Parameters to some God-Damn Participants

#Clean previous variables and set starting variables
rm(list = ls())

#Required packages and files----
require('tidyverse')
require('nloptr')
require('rtdists')
source('BanditFit.R', TRUE)
source('RW.R', TRUE)
source('KalmanFilter.R', TRUE)
source('LBASim.R', TRUE)
source('addUnc.R', TRUE)
source('runBandit_All.R', TRUE)

#Parameter info ----
#A is the start-point for each option, let all As be different initially to account for bias (1-4)
#B is the bound. To keep things identifiable, make the bound set across all arms (5)
#T0 is the amount of Non-decision time (6)
#THETA is the temperature parameter for all models (7)
#QSTART is a free parameter and helps determine whether participants will be optimistic or not at the beginning by determining starting values (8)
#ZETA is the prospect theory power (9)
#DELTA is the loss-aversion parameter (10)
#ALPHA_POS is the learning rate parameter for RW in the positive direction (Pedersen et al., 2017) (11)
#ALPHA_NEG is the learning rate parameter for RW in the negative direction (Pedersen et al., 2017) (12)
#SD_V is the drift-rate parameter, again we'll keep this constant (unless we're testing a model where we alter it) (13)
#UNCSTART is where uncertainty expectations start at (14)
#GAMMA is a general parameter that transforms uncertainty (although it will act differently in different models) (15)
#Practice Params
params <- c(.5, .5, .5, .5, 1, .2, 1, 20, 1, 1, .5, .5, .3, 100, 10.5)


#Set fit information ----
pNum = 80
allData <- read_csv('S&KData.csv')
params <- matrix(ncol = 16, nrow = pNum)
NLLs <- matrix(ncol = 2, nrow = pNum)

#Start the fit for individual participants ----
#id is four participants (one for each condition)
#id2 is an individual participant
for (p in 1:pNum) {
  #select the useful data
  pData <- filter(allData, id2 == p) %>% 
    select(trial, deck, payoff, rt, block, cond)
  
  #Optimisation options, first rough pass
  opts <- list("algorithm"="NLOPT_GN_DIRECT",
               "maxeval" = 200)
  
  # mle(CMABFit(params = startPoint, rawData = rawData), start = list(params = startPoint), fixed = list('rawData'))
  param <- nloptr(x0 = c(.5, .5, .5, .5, 1, .2, 1, 20, 1, 1, .5, .5, .3, 100, 10), 
                  eval_f = BanditFit, 
                  lb = c(0, 0, 0, 0, 0, 0, .01, -100, -5, -5, 0.05, 0.05, 0, 0, .01), 
                  ub = c(5, 5, 5, 5, 5, 1000, 10, 100, 5, 5, 1, 1, 5, 100, 20), 
                  opt = opts, rawData = pData, learnType = 'RW', whichLBA = 1, bonusStyle = 1)
  
  #Optimisation options, second finer pass using parameters found previously
  opts <- list("algorithm"="NLOPT_GN_DIRECT_L",
               "maxeval" = 200)
  
  # mle(CMABFit(params = startPoint, rawData = rawData), start = list(params = startPoint), fixed = list('rawData'))
  paramFine <- nloptr(x0 = param$solution, 
                  eval_f = BanditFit, 
                  lb = c(0, 0, 0, 0, 0, 0, .01, -100, -5, -5, 0.05, 0.05, 0, 0, .01), 
                  ub = c(5, 5, 5, 5, 5, 1000, 10, 100, 5, 5, 1, 1, 5, 100, 20),
                  opt = opts, rawData = pData, learnType = 'RW', whichLBA = 1, bonusStyle = 1)
  
  params[p, 1] <- factor(pNum)
  params[p, 2:16] <- paramFine$solution
  NLLs[p, 1] <- factor(pNum)
  NLLs[p, 2] <- BanditFit(paramFine$solution, rawData = pData, learnType = 'RW', whichLBA = 1, bonusStyle = 1)
  
  
}

