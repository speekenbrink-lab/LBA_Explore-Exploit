#Simulate Sudden Uncertainty Onset
# library('tidyverse')
# setwd('C:/Users/awalk/OneDrive/Documents/PhD/London/LBA-Code')

#Set parameters (all in caps)
#Start-point bound
A <-param$par[1]
#Threshold
B <- param$par[2]
#Decision Delay
T0 <- param$par[3]
#Standard Deviation
SD_V <- param$par[4]
#Learning Rate
ALPHA <- param$par[5]
#Rate transformation from scores (Similar to a temperature parameter)
PHI <- param$par[7]
#Starting values
QSTART <- param$par[6]

#Number of simulations
simNum = 5000

#Number of trials
trialNum = 448

#Optimality tracker
simList <- matrix(ncol = simNum, nrow = trialNum)

for (p in 1:simNum) {
  sim <- runPart(A, B, T0, SD_V, ALPHA, PHI, QSTART)
  simList[1:trialNum, p] <- sim$optimal
}

condensedList <- apply(simList, 1, mean)

condensedList <- data.frame(trial = 1:trialNum, averageScore = condensedList)

ggplot(data = condensedList, mapping = aes(x = trial, y = averageScore, group = 1)) +
  geom_line() +
  coord_cartesian(ylim = c(.3, 1))

runPart = function(A, B, T0, SD_V, ALPHA, PHI, QSTART) {
  #A is start-point bound
  #B is threshold
  #T0 is decision delay
  #SD_V is the standard deviation of the drift rate
  #ALPHA is the learning rate
  #PHI is the score transformation and acts like a temperature parameter
  #QSTART is the starting value of all responses
  
  #Set initial task information
  trialNum <- 448
  #Qs for each action for each Cue, cols 1:4 are for response 1, cols 5:8 are for response 2
  Qs <- rep(QSTART, times = 8)
  test <- data.frame(choice = 0, rts = 0, rewards = 0, optimal = 0)
  QTable <- matrix(ncol = 8, nrow = trialNum)
  #Trial sequence
  trialSeq <- array(c(1, 1, 2, 2, 3, 4, 3, 4), dim=c(4, 2))
  trialSeq <- matrix(rep(t(trialSeq), trialNum/4) , ncol = ncol(trialSeq), byrow = TRUE)
  #Mean values for each response given the cues
  trialVals <- rep(0, times = 2)
  
  #Run Trials
  for (t in 1:trialNum){
    #Which cues are on screen
    cuesPres <- rep(NA, times = 4)
    #Find cues in the trial
    cuesPres[trialSeq[t, 1]] <- 1
    cuesPres[trialSeq[t, 2]] <- 1
    
    QTable[t, 1:8] <- Qs
    
    #Transform presented cues for values for each choice
    trialVals[1] <- mean(cuesPres*Qs[1:4], na.rm = TRUE)
    trialVals[2] <- mean(cuesPres*Qs[5:8], na.rm = TRUE)
    
    #Transform expected value into mean-driftrate
    driftRates <- (trialVals + 0)/PHI
    
    #Run LBA
    test[t, 1:2] <- LBASim(A, B, T0, driftRates, SD_V, length(trialVals))
    
    #Get Reward dependant on choice
    #observedReward <- c(0, 0, 0, 0)
    if (test$choice[t] == 1 & 1 %in% trialSeq[t, 1:2]) {
      observedReward <- 15
      optimal <- 1
    } else if (test$choice[t] == 2 & 2 %in% trialSeq[t, 1:2]) {
      observedReward <- 15
      optimal <- 1
    } else {
      observedReward <- 10
      optimal <- 0
    }
    
    if (t > 256) {
      observedReward <- observedReward + sample(-7:7, 1)
    }
    
    test[t, 3] = observedReward
    test[t, 4] = optimal
  
    #Learn based on decision
    if (test$choice[t] == 1) {
      Qs[1:4] <- RW(ALPHA, Qs[1:4], observedReward, cuesPres)
    } else if (test$choice[t] == 2) {
      Qs[5:8] <- RW(ALPHA, Qs[5:8], observedReward, cuesPres)
    }
      
  }
  
  test$choice <- as.factor(test$choice)
  
  #Plot choices
  #ggplot(data = test, mapping = aes(x = rts, fill = choice)) +
    #geom_histogram(binwidth = .2) +
    #coord_cartesian(xlim = c(0, 10))
  return(test)
}

#Learning Model
RW <- function(ALPHA, oldQs, observedReward, cuesPres) {
  newQs <- ALPHA * (observedReward - sum(oldQs * cuesPres, na.rm = TRUE)) / sum(cuesPres, na.rm = TRUE)
  newQs <- cuesPres * newQs
  newQs[is.na(newQs)] <- 0
  newQs <- oldQs + newQs
  
  return(newQs)
}
  

#RT Decision model
LBASim <- function(A, B, T0, mean_v, SD_V, choiceNum) {#Simulate LBA model
  #n = number of participants
  #A = Starting point upper bound
  #b = threshold
  #t0 = start delay
  #mean_v = mean driftrate for each option
  #sd_v = mean standard deviation for each option
  
  #Simulate some trials
  
  choice <- 0
  rts <- 0
  sim <- 0
  
    trialFine <- 0
    while (!trialFine) {
      #Get Start point
      start <- runif(1, 0, A)
      drift <- 0
      time <- 0
      
      for (m in 1:choiceNum) {
      #Get Drift Rates
        drift[m] <- rnorm(1, mean_v[m], SD_V)
        
        #Get time to threshold
        time[m] <- (B - start) / drift[m]
        
        #Add non-decision time
        time[m] = time[m] + T0
      }
      
      #Check we don't have negative times (Make sure to change this to correspond to the number of choices available)
      if (sum(time > 0) == length(time)) {
        trialFine = 1
      }
    }
    
    #Make choice based on values
    choice <- which.min(time)
    rts <- min(time)
  
  sim <- data.frame(choice, rts)
  
  return(sim)
}

