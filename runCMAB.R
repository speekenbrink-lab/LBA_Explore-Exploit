runCMAB <- function(params, trialNum, rawData, simOrTest, S2QStart) {
  #Assign params to values ----
  #A is the start-point for each option, let all As be different initially to account for bias
  A = rep(0, 4)
  A[1] <- params[1]
  A[2] <- params[2]
  
  #B is the bound. To keep things identifiable, make the bound set across all arms
  B <- params[3]
  
  #T0 is the amount of Non-decision time
  T0 <- params[4]
  
  #THETA is the temperature parameter for all models
  THETA <- params[5]
  
  #QSTART is a free parameter and helps determine whether participants will be optimistic or not at the beginning by determining starting values
  if (any(is.nan(S2QStart))){
    QSTART <- rep(params[6], 8)
  } else {
    QSTART <- S2QStart
  }
  
  #ZETA is the prospect theory power
  ZETA <- params[7]
  
  #DELTA is the loss-aversion parameter
  DELTA <- params[8]
  
  #ALPHA_POS is the learning rate parameter for RW in the positive direction (Pedersen et al., 2017)
  ALPHA_POS <- params[9]
  #ALPHA_NEG is the learning rate parameter for RW in the negative direction (Pedersen et al., 2017)
  ALPHA_NEG <- params[10]
  
  #SD_V is the drift-rate parameter, again we'll keep this constant (unless we're testing a model where we alter it)
  SD_V <- rep(params[11], 2)
  
  #UNCSTART is where uncertainty expectations start at 
  UNCSTART <- rep(params[12], 2)
  
  #GAMMA is a general parameter that transforms uncertainty (although it will act differently in different models)
  GAMMA <- params[13]
  
  #preallocate variables ----
  choiceNum = 2
  
  #Perform Learning in Trials
  
  #Q values for each action
  #Qs are for EVs
  Qs <- QSTART
  QTable <- matrix(ncol = 8, nrow = trialNum)
  driftRates <- rep(0, 2)
  #See what values have been observed on which options
  valuesObserved <- matrix(ncol = 8, nrow = trialNum)
  #Uncertainty tracker
  Uncs <- UNCSTART
  tempUncs <- UNCSTART
  UncTable <- matrix(ncol = 8, nrow = trialNum)
  tempUncTable <- matrix(ncol = 8, nrow = trialNum)
  #Mean values for each response given the cues
  trialVals <- rep(0, times = 2)
  #Likelihoods of the response
  likelihood <- rep(0, times = trialNum)
  
  Sim <-  data.frame(choice = 0, rts = 0, rewards = 0, optimal = 0, EV_Diff = 0, Unc_Max = 0)

  #Create trial Structute ----
  cueArray <- matrix(ncol = 2, nrow = trialNum)
  rewards <- matrix(ncol = 1, nrow = trialNum)
  if (simOrTest == 'Sim') {
    holder <- rbind(c(1, 3),
                    c(1, 4),
                    c(2, 3),
                    c(2, 4))
    for (t in 1:(trialNum/4)){
      holder <- holder[sample(4),]
      cueArray[((t-1) * 4 + 1):(t*4),] <- holder
    }
    for (t in 1:trialNum) {
      rewards[t] <- runif(1, min = -7.5, max = 7.5)
    }
    rewards <- round(rewards)
  } else if (simOrTest == 'Test') {
    cueArray <- cbind(rawData$cueOne, rawData$cueTwo)
    rewards <- rawData$reward
  }
  
  #Run Trials ----
  for (t in 1:(trialNum)){
    #Which cues are on screen
    cuesPres <- rep(NA, times = 4)
    #Find cues in the trial
    cuesPres[cueArray[t, 1]] <- 1
    cuesPres[cueArray[t, 2]] <- 1
    
    QTable[t, 1:8] <- Qs
    
    #Transform presented cues for values for each choice
    trialVals[1] <- mean(cuesPres*QTable[t, 1:4], na.rm = TRUE)
    trialVals[2] <- mean(cuesPres*QTable[t, 5:8], na.rm = TRUE)

    #Earn Reward
    if (simOrTest == 'Sim'){
      #Transform expected value into mean-driftrate
      for (e in 1:2) {
        driftRates[e] <-  exp(trialVals[e]/THETA) / sum(exp(trialVals/THETA))
      }
      #Make Decision
      Sim[t, 1:2] <- LBASim(A, B, T0, driftRates, SD_V, 2)
      choice <-  Sim$choice[t]
      
      #Transform presented cues for values for each choice
      trialVals[1] <- mean(cuesPres*QTable[t, 1:4], na.rm = TRUE)
      trialVals[2] <- mean(cuesPres*QTable[t, 5:8], na.rm = TRUE)
      
      #Transform expected value into mean-driftrate
      for (e in 1:2) {
        driftRates[e] <-  exp(trialVals[e]/THETA) / sum(exp(trialVals/THETA))
      }
      
      #Make Decision
      Sim[t, 1:2] <- LBASim(A, B, T0, driftRates, SD_V, 2)
      choice = Sim$choice[t]
      
      if (choice == 1 & 1 %in% cueArray[t, 1:2]) {
        observedReward <- 15 + rewards[t]
        optimal <- 1
      } else if (choice == 2 & 2 %in% cueArray[t, 1:2]) {
        observedReward <- 15 + rewards[t]
        optimal <- 1
      } else {
        observedReward <- 10 + rewards[t]
        optimal <- 0
      }
      Sim$rewards[t] <- observedReward
      Sim$optimal[t] <- optimal
      Sim$EV_Diff[t] <- abs(trialVals[1] - trialVals[2])
      Sim$Unc_Max[t] <- 0 #JUst for testing
      
    } else if (simOrTest == 'Test'){
      observedReward <-  rewards[t]
      choice <- rawData$choice[t]
    }
    
    #Calculate Utility and Learn
    if (rewards[t] >= 0) {
      utility <- observedReward ^ ZETA
    } else {
      utility <- -DELTA * ((abs(observedReward)) ^ ZETA)
    }
    
    PE = utility - sum(Qs * cuesPres, na.rm = TRUE)
    if (PE < 0) {
      ALPHA = ALPHA_NEG
    } else {
      ALPHA = ALPHA_POS
    }
    
    if (choice == 1) {
      Qs[1:4] <- RW(ALPHA, Qs[1:4], observedReward, cuesPres)
    } else if (choice == 2) {
      Qs[5:8] <- RW(ALPHA, Qs[5:8], observedReward, cuesPres)
    }
  }
  
  if (simOrTest == 'Sim'){
    return(Sim)
  } else if (simOrTest == 'Test'){
    return(QTable[t,])
  }
  
}